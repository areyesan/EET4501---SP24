{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5iJyjIYWqcjy"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# GPT2 Text Generation with KerasNLP\n"
      ],
      "metadata": {
        "id": "w07IVUtmt6z4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this tutorial, you will learn to use [KerasNLP](https://keras.io/keras_nlp/) to load a\n",
        "pre-trained Large Language Model (LLM) - [GPT-2 model](https://openai.com/research/better-language-models)\n",
        "(originally invented by OpenAI)"
      ],
      "metadata": {
        "id": "mgW_0M15t69X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install KerasNLP, Choose Backend and Import Dependencies\n",
        "\n",
        "This examples uses [Keras Core](https://keras.io/keras_core/) to work in any of\n",
        "`\"tensorflow\"`, `\"jax\"` or `\"torch\"`. Support for Keras Core is baked into\n",
        "KerasNLP, simply change the `\"KERAS_BACKEND\"` environment variable to select\n",
        "the backend of your choice. We select the JAX backend below."
      ],
      "metadata": {
        "id": "wh6rR1FDt7IP"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RcoE4otzuEoV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/keras-team/keras-nlp.git -q"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PJTKBsmvuClW",
        "outputId": "bc70619a-2292-4484-8067-b5ac1d052262"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m950.8/950.8 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.2/5.2 MB\u001b[0m \u001b[31m33.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m589.8/589.8 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.8/4.8 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m311.2/311.2 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for keras-nlp (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tf-keras 2.15.1 requires tensorflow<2.16,>=2.15, but you have tensorflow 2.16.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"KERAS_BACKEND\"] = \"jax\"  # or \"tensorflow\" or \"torch\"\n",
        "\n",
        "import keras_nlp\n",
        "import keras\n",
        "import tensorflow as tf\n",
        "import time\n",
        "\n",
        "keras.mixed_precision.set_global_policy(\"mixed_float16\")"
      ],
      "metadata": {
        "id": "2TzyY6u-uCn-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PNGNl40SuCqf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Introduction to Generative Large Language Models (LLMs)\n",
        "\n",
        "Large language models (LLMs) are a type of machine learning models that are\n",
        "trained on a large corpus of text data to generate outputs for various natural\n",
        "language processing (NLP) tasks, such as text generation, question answering,\n",
        "and machine translation.\n",
        "\n",
        "Generative LLMs are typically based on deep learning neural networks, such as\n",
        "the [Transformer architecture](https://arxiv.org/abs/1706.03762) invented by\n",
        "Google researchers in 2017, and are trained on massive amounts of text data,\n",
        "often involving billions of words. These models, such as Google [LaMDA](https://blog.google/technology/ai/lamda/)\n",
        "and [PaLM](https://ai.googleblog.com/2022/04/pathways-language-model-palm-scaling-to.html),\n",
        "are trained with a large dataset from various data sources which allows them to\n",
        "generate output for many tasks. The core of Generative LLMs is predicting the\n",
        "next word in a sentence, often referred as **Causal LM Pretraining**. In this\n",
        "way LLMs can generate coherent text based on user prompts. For a more\n",
        "pedagogical discussion on language models, you can refer to the\n",
        "[Stanford CS324 LLM class](https://stanford-cs324.github.io/winter2022/lectures/introduction/)."
      ],
      "metadata": {
        "id": "9_lHhu9AuKXG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load a pre-trained GPT-2 model and generate some text\n",
        "\n",
        "KerasNLP provides a number of pre-trained models, such as [Google\n",
        "Bert](https://ai.googleblog.com/2018/11/open-sourcing-bert-state-of-art-pre.html)\n",
        "and [GPT-2](https://openai.com/research/better-language-models). You can see\n",
        "the list of models available in the [KerasNLP repository](https://github.com/keras-team/keras-nlp/tree/master/keras_nlp/models).\n",
        "\n",
        "It's very easy to load the GPT-2 model as you can see below:"
      ],
      "metadata": {
        "id": "khzc4lXBuRPe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# To speed up training and generation, we use preprocessor of length 128\n",
        "# instead of full length 1024.\n",
        "preprocessor = keras_nlp.models.GPT2CausalLMPreprocessor.from_preset(\n",
        "    \"gpt2_base_en\",\n",
        "    sequence_length=128,\n",
        ")\n",
        "gpt2_lm = keras_nlp.models.GPT2CausalLM.from_preset(\n",
        "    \"gpt2_base_en\", preprocessor=preprocessor\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MHVLAhNVuCtO",
        "outputId": "bc94ba24-04b7-47b2-ac31-947d9907bbb5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/models/keras/gpt2/keras/gpt2_base_en/2/download/tokenizer.json...\n",
            "100%|██████████| 448/448 [00:00<00:00, 934kB/s]\n",
            "Downloading from https://www.kaggle.com/api/v1/models/keras/gpt2/keras/gpt2_base_en/2/download/assets/tokenizer/merges.txt...\n",
            "100%|██████████| 446k/446k [00:00<00:00, 2.96MB/s]\n",
            "Downloading from https://www.kaggle.com/api/v1/models/keras/gpt2/keras/gpt2_base_en/2/download/assets/tokenizer/vocabulary.json...\n",
            "100%|██████████| 0.99M/0.99M [00:00<00:00, 5.50MB/s]\n",
            "Downloading from https://www.kaggle.com/api/v1/models/keras/gpt2/keras/gpt2_base_en/2/download/config.json...\n",
            "100%|██████████| 484/484 [00:00<00:00, 93.0kB/s]\n",
            "Downloading from https://www.kaggle.com/api/v1/models/keras/gpt2/keras/gpt2_base_en/2/download/model.weights.h5...\n",
            "100%|██████████| 475M/475M [00:10<00:00, 46.5MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Once the model is loaded, you can use it to generate some text right away. Run the cells below to give it a try. It's as simple as calling a single function generate():"
      ],
      "metadata": {
        "id": "S45OxEtRuX3m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "start = time.time()\n",
        "\n",
        "output = gpt2_lm.generate(\"My trip to Yosemite was\", max_length=200)\n",
        "print(\"\\nGPT-2 output:\")\n",
        "print(output)\n",
        "\n",
        "end = time.time()\n",
        "print(f\"TOTAL TIME ELAPSED: {end - start:.2f}s\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "21gWe76PuCvd",
        "outputId": "209cedfa-52c1-4a8c-97e3-9f82948df4c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "GPT-2 output:\n",
            "My trip to Yosemite was one of my most memorable. I've been to every major park, and Yosemite is my favorite. It's a beautiful area with a variety of trails and wildlife that I've never experienced anywhere else. I've seen so many amazing things here, and I'm sure you'll love the views and the views of the mountains.\n",
            "\n",
            "I was lucky to have the chance to visit Yosemite on my first day, and it was amazing! There's a lot to do and see in the area and the weather is perfect for hiking. I was very happy to see that there was a large, beautiful tree canopy that I've never seen before on the trail. It looked like it might have been planted in the ground. I also saw some of the most amazing wildlife that you will ever see in a place like Yosemite.\n",
            "\n",
            "The trail to Yosemite is very long and very winding. There are many trails that run along the trail to get to the summit and the summit of\n",
            "TOTAL TIME ELAPSED: 50.50s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "z41gE2NjuCxm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Try another one:"
      ],
      "metadata": {
        "id": "CP1p59Suucdm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "start = time.time()\n",
        "\n",
        "output = gpt2_lm.generate(\"That Italian restaurant is\", max_length=200)\n",
        "print(\"\\nGPT-2 output:\")\n",
        "print(output)\n",
        "\n",
        "end = time.time()\n",
        "print(f\"TOTAL TIME ELAPSED: {end - start:.2f}s\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VCjXu8BMuCz2",
        "outputId": "f23999e5-df6e-487b-9b74-2318bb414c6a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "GPT-2 output:\n",
            "That Italian restaurant is known for its delicious and flavorful food. It was founded as a restaurant in the early 1900s, with its first restaurant opened in the 1930s.\n",
            "\n",
            "It is now a popular destination for families, as it has been for many years.\n",
            "\n",
            "But it has a history of bad behavior, and a history of bad food.\n",
            "\n",
            "The restaurant has been shuttered for over a decade.\n",
            "\n",
            "The Italian restaurant was opened to the public in the late 1980s as a way to raise awareness of the problem of food safety in Italy.\n",
            "\n",
            "It is now owned by the family of the late Italian chef, Giovanni Visconti.\n",
            "TOTAL TIME ELAPSED: 20.98s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "q0-BJ3UNu463"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Last one:"
      ],
      "metadata": {
        "id": "icFlBvNEt7LG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "start = time.time()\n",
        "\n",
        "output = gpt2_lm.generate(\"Michigan Technological University is\", max_length=200)\n",
        "print(\"\\nGPT-2 output:\")\n",
        "print(output)\n",
        "\n",
        "end = time.time()\n",
        "print(f\"TOTAL TIME ELAPSED: {end - start:.2f}s\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pyPtLYmYu6j-",
        "outputId": "4f3b073e-6f49-49c9-a16f-8e581e2e5adb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "GPT-2 output:\n",
            "Michigan Technological University is a leader in the field of computer vision and machine learning. It is home to a wide array of research institutes, including the Michigan Institute of Technology, the University of Michigan School of Engineering and Applied Science, and a number of other institutions.\n",
            "\n",
            "The university's research is funded in part by federal grant money and is supported by the National Science Foundation (NSF).\n",
            "\n",
            "Michigan Technological University is located at 825 W. University Ave. in Michigan City.\n",
            "\n",
            "About The Michigan Technological University\n",
            "\n",
            "In 2015, Michigan Technological University was ranked #1 in the country by the National Science Foundation. It is a leader in the field of computer vision and machine learning, and one of the nation's leading universities in computer vision and machine learning, with more than 50,000 students enrolled each semester. The school also has more than 50,000 faculty and more than 100,000 students enrolled annually, with over 2,500 full-time and\n",
            "TOTAL TIME ELAPSED: 27.95s\n"
          ]
        }
      ]
    }
  ]
}